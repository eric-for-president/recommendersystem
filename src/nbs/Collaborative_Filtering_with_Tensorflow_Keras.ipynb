{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTesJKHwtrA"
      },
      "source": [
        "# Collaborative Filtering using Tensorflow & Keras\n",
        "In our [Recommender Course](https://www.codingforentrepreneurs.com/courses/recommender/) we build a Django-based recommendation engine leveraging the Surprise ML package (among other things). This guide is made to help you upgrade your ML package by leveraging Keras and a neural network.\n",
        "\n",
        "\n",
        "Recommended requirements for running this notebook:\n",
        "- GPU-accelerated / CUDA-enabled environment\n",
        "- Cloud-based service such as Google Colab, Deepnote, and/or Paperspace\n",
        "- [Recommender]((https://github.com/codingforentrepreneurs/recommender)) code forked/cloned/downloaded, open-source datasets loaded in, and Recommender models exported\n",
        "- To export the [Recommender](https://github.com/codingforentrepreneurs/recommender)'s datasets, you can run the functions `export_rating_dataset_task` and `export_movies_dataset_task` in the `exports/tasks.py`\n",
        "-  After you run these functions, you'll have the movies dataset located in `local-cdn/media/exports/movies/latest.csv` and the ratings dataset in `local-cdn/media/exports/ratings/latest.csv`\n",
        "\n",
        "\n",
        "\n",
        "This code was directly inspired and modified from the following posts:\n",
        "- [Fast.ai's Collaborative Filtering Lesson](https://course.fast.ai/Lessons/lesson7.html)\n",
        "- [How to create a Recommendation System from scratch using Keras from the Antonai Blog](https://antonai.blog/how-to-create-a-recommendation-system-from-scratch-using-keras/)\n",
        "- [Collaborative Filtering for Movie Recommendations the Keras Docs](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
        "\n",
        "\n",
        "### Open this notebook in...\n",
        "\n",
        "[<img src=\"https://deepnote.com/buttons/launch-in-deepnote-white-small.svg\">](https://deepnote.com/launch?url=https://github.com/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)\n",
        "\n",
        "[![Run on Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY4HpIQrwtrI",
        "outputId": "d8b79843-e48e-4777-e476-8dfa02a7df79"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow scikit-learn matplotlib pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:09.946362Z",
          "iopub.status.busy": "2022-09-21T17:06:09.946069Z",
          "iopub.status.idle": "2022-09-21T17:06:09.950651Z",
          "shell.execute_reply": "2022-09-21T17:06:09.950028Z",
          "shell.execute_reply.started": "2022-09-21T17:06:09.946342Z"
        },
        "id": "HCvzSnGbZKs4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:09.960324Z",
          "iopub.status.busy": "2022-09-21T17:06:09.960104Z",
          "iopub.status.idle": "2022-09-21T17:06:09.964650Z",
          "shell.execute_reply": "2022-09-21T17:06:09.964029Z",
          "shell.execute_reply.started": "2022-09-21T17:06:09.960307Z"
        },
        "id": "WGAfanL1wtrL",
        "outputId": "a2cfbc23-b039-4e4d-d301-3b59c2d83fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False False\n"
          ]
        }
      ],
      "source": [
        "# if using a cloud provider, upload your files to an \"exports folder\"\n",
        "# exports_dir = pathlib.Path().resolve() / 'exports'\n",
        "\n",
        "# if running this notebook from the root of the Recommender project\n",
        "exports_dir = pathlib.Path().resolve().parent / \"local-cdn\" / \"media\" / \"exports\"\n",
        "\n",
        "movies_exports = exports_dir / \"movies\" / \"latest.csv\"\n",
        "ratings_exports = exports_dir / \"ratings\" / \"latest.csv\"\n",
        "print(movies_exports.exists(), ratings_exports.exists())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjeEpex2wtrM"
      },
      "source": [
        "Load in the movies dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:09.966139Z",
          "iopub.status.busy": "2022-09-21T17:06:09.965948Z",
          "iopub.status.idle": "2022-09-21T17:06:10.017754Z",
          "shell.execute_reply": "2022-09-21T17:06:10.016986Z",
          "shell.execute_reply.started": "2022-09-21T17:06:09.966124Z"
        },
        "id": "tqJk3h-twtrM",
        "outputId": "4c29990b-c328-4f50-b788-42ab74eb5556"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/local-cdn/media/exports/movies/latest.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-37a2a69338e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_exports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# add a \"trend\" column to combine the count of ratings with the movie's average rating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieIdx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieIdx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/local-cdn/media/exports/movies/latest.csv'"
          ]
        }
      ],
      "source": [
        "movies_df = pd.read_csv(movies_exports)\n",
        "\n",
        "# add a \"trend\" column to combine the count of ratings with the movie's average rating\n",
        "movies_df[\"trend\"] = movies_df[\"rating_count\"] * movies_df[\"rating_avg\"]\n",
        "movies_df[\"movieIdx\"] = movies_df[\"movieIdx\"].astype(int)\n",
        "movies_df[\"movieId\"] = movies_df[\"movieId\"].astype(int)\n",
        "\n",
        "print(movies_df.shape)\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mYlYVxSwtrN"
      },
      "source": [
        "Load in the entire ratings dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.019295Z",
          "iopub.status.busy": "2022-09-21T17:06:10.019034Z",
          "iopub.status.idle": "2022-09-21T17:06:10.039846Z",
          "shell.execute_reply": "2022-09-21T17:06:10.039211Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.019273Z"
        },
        "id": "yFwTglLpwtrO"
      },
      "outputs": [],
      "source": [
        "rating_df = pd.read_csv(ratings_exports)\n",
        "print(rating_df.shape)\n",
        "rating_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAgumVCEwtrO"
      },
      "source": [
        "Join the movies dataset and ratings dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.040852Z",
          "iopub.status.busy": "2022-09-21T17:06:10.040662Z",
          "iopub.status.idle": "2022-09-21T17:06:10.074145Z",
          "shell.execute_reply": "2022-09-21T17:06:10.073404Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.040836Z"
        },
        "id": "TnIa_D0hwtrP"
      },
      "outputs": [],
      "source": [
        "df = rating_df.copy()\n",
        "df[\"userId\"] = df[\"userId\"].astype(int)\n",
        "df[\"movieId\"] = df[\"movieId\"].astype(int)\n",
        "df = df.join(movies_df, on=\"movieId\", rsuffix=\"_movie_df\")\n",
        "df.sort_values(by=[\"trend\"], inplace=True, ascending=False)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wlTB4C1wtrQ"
      },
      "source": [
        "Make note of the missing number of movies from the ratings dataset. These are missing for a couple reasons:\n",
        "- Initial dataset used had invalid ids (from the movielens datasset) - Most likely\n",
        "- Movies have been deleted from the Recommender database - Likely\n",
        "- Incorrect datatypes - Unlikely but possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.075958Z",
          "iopub.status.busy": "2022-09-21T17:06:10.075767Z",
          "iopub.status.idle": "2022-09-21T17:06:10.085651Z",
          "shell.execute_reply": "2022-09-21T17:06:10.085017Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.075943Z"
        },
        "id": "AaUnyIxxwtrQ"
      },
      "outputs": [],
      "source": [
        "missing_data = df[df[\"movieIdx\"].isna()]\n",
        "\n",
        "number_of_missing_movies = len(missing_data.movieId.unique().tolist())\n",
        "print(number_of_missing_movies, \"movie ids missing that were rated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpQznFNxwtrQ"
      },
      "source": [
        "Drop `NaN` columns that lack a `movieIdx` value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.086700Z",
          "iopub.status.busy": "2022-09-21T17:06:10.086512Z",
          "iopub.status.idle": "2022-09-21T17:06:10.111342Z",
          "shell.execute_reply": "2022-09-21T17:06:10.110841Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.086686Z"
        },
        "id": "R010Bsj2wtrR"
      },
      "outputs": [],
      "source": [
        "training_df = df.copy().dropna()\n",
        "training_df[\"movieIdx\"] = training_df[\"movieIdx\"].astype(int)\n",
        "training_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.112412Z",
          "iopub.status.busy": "2022-09-21T17:06:10.112233Z",
          "iopub.status.idle": "2022-09-21T17:06:10.129617Z",
          "shell.execute_reply": "2022-09-21T17:06:10.129112Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.112397Z"
        },
        "id": "j6OY-vuCwtrR"
      },
      "outputs": [],
      "source": [
        "user_ids = training_df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "\n",
        "\n",
        "movie_ids = training_df[\"movieIdx\"].unique().tolist()\n",
        "\n",
        "df = training_df.copy()\n",
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"movie\"] = df[\"movieIdx\"]\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_ids)\n",
        "\n",
        "df[\"rating\"] = training_df[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "min_rating = min(df[\"rating\"])\n",
        "max_rating = max(df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.130513Z",
          "iopub.status.busy": "2022-09-21T17:06:10.130312Z",
          "iopub.status.idle": "2022-09-21T17:06:10.153283Z",
          "shell.execute_reply": "2022-09-21T17:06:10.152775Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.130497Z"
        },
        "id": "Ecgcp--6wtrS"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.154113Z",
          "iopub.status.busy": "2022-09-21T17:06:10.153932Z",
          "iopub.status.idle": "2022-09-21T17:06:10.201159Z",
          "shell.execute_reply": "2022-09-21T17:06:10.200590Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.154098Z"
        },
        "id": "F9pNMUzWwtrS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Embedding,\n",
        "    multiply,\n",
        "    concatenate,\n",
        "    Flatten,\n",
        "    Input,\n",
        "    Dense,\n",
        ")\n",
        "\n",
        "from tensorflow.keras import optimizers as opt\n",
        "\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "EMBEDDING_SIZE = 500\n",
        "\n",
        "num_unique_users = num_users\n",
        "\n",
        "num_unique_movies = num_movies\n",
        "\n",
        "users_input = Input(shape=(1,), name=\"users_input\")\n",
        "\n",
        "users_embedding = Embedding(\n",
        "    num_unique_users + 1, EMBEDDING_SIZE, name=\"users_embeddings\"\n",
        ")(users_input)\n",
        "\n",
        "users_bias = Embedding(num_unique_users + 1, 1, name=\"users_bias\")(users_input)\n",
        "\n",
        "\n",
        "movies_input = Input(shape=(1,), name=\"movies_input\")\n",
        "\n",
        "movies_embedding = Embedding(\n",
        "    num_unique_movies + 1, EMBEDDING_SIZE, name=\"movies_embedding\"\n",
        ")(movies_input)\n",
        "\n",
        "movies_bias = Embedding(num_unique_movies + 1, 1, name=\"movies_bias\")(movies_input)\n",
        "\n",
        "\n",
        "dot_product_users_movies = multiply([users_embedding, movies_embedding])\n",
        "\n",
        "input_terms = dot_product_users_movies + users_bias + movies_bias\n",
        "\n",
        "input_terms = Flatten(name=\"fl_inputs\")(input_terms)\n",
        "\n",
        "# output = Dense(1, activation=\"relu\", name=\"output\")(input_terms)\n",
        "\n",
        "\n",
        "output = Dense(1, activation=\"sigmoid\", name=\"output\")(input_terms)\n",
        "\n",
        "output = output * (max_rating - min_rating) + min_rating\n",
        "\n",
        "\n",
        "\n",
        "model = Model(inputs=[users_input, movies_input], outputs=output)\n",
        "\n",
        "\n",
        "opt_adam = opt.Adam(learning_rate=0.005)\n",
        "\n",
        "model.compile(optimizer=opt_adam, loss=[\"mse\"], metrics=[\"mean_absolute_error\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:07:27.863315Z",
          "iopub.status.busy": "2022-09-21T17:07:27.862678Z",
          "iopub.status.idle": "2022-09-21T17:07:27.883267Z",
          "shell.execute_reply": "2022-09-21T17:07:27.882685Z",
          "shell.execute_reply.started": "2022-09-21T17:07:27.863292Z"
        },
        "id": "50aTKr0OwtrT"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:10.202063Z",
          "iopub.status.busy": "2022-09-21T17:06:10.201888Z",
          "iopub.status.idle": "2022-09-21T17:06:10.224755Z",
          "shell.execute_reply": "2022-09-21T17:06:10.224197Z",
          "shell.execute_reply.started": "2022-09-21T17:06:10.202048Z"
        },
        "id": "a5tLJS2SwtrT"
      },
      "outputs": [],
      "source": [
        "df_train, df_val = train_test_split(\n",
        "    df, random_state=42, test_size=0.2, stratify=df.rating\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:06:50.781014Z",
          "iopub.status.busy": "2022-09-21T17:06:50.780612Z",
          "iopub.status.idle": "2022-09-21T17:07:02.851920Z",
          "shell.execute_reply": "2022-09-21T17:07:02.851282Z",
          "shell.execute_reply.started": "2022-09-21T17:06:50.780993Z"
        },
        "id": "2FSi1D5rwtrT"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x=[df_train.user.to_numpy(), df_train.movie.to_numpy()],\n",
        "    y=df_train.rating.to_numpy(),\n",
        "    batch_size=200,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(\n",
        "        [df_val.user.to_numpy(), df_val.movie.to_numpy()],\n",
        "        df_val.rating.to_numpy(),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:13:32.391219Z",
          "iopub.status.busy": "2022-09-21T17:13:32.390726Z",
          "iopub.status.idle": "2022-09-21T17:13:32.445178Z",
          "shell.execute_reply": "2022-09-21T17:13:32.444683Z",
          "shell.execute_reply.started": "2022-09-21T17:13:32.391197Z"
        },
        "id": "Uu1-z7-kwtrT"
      },
      "outputs": [],
      "source": [
        "number_of_preds = 100\n",
        "movies = df.sample(n=number_of_preds).movie.to_list()\n",
        "user_list = df.sample(n=1).user.to_list() * number_of_preds\n",
        "use_id = False\n",
        "if use_id:\n",
        "    user_list = [user2user_encoded.get(1)] * number_of_preds\n",
        "preds = model.predict(x=[np.array(user_list), np.array(movies)])\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:13:46.311869Z",
          "iopub.status.busy": "2022-09-21T17:13:46.311258Z",
          "iopub.status.idle": "2022-09-21T17:13:46.321652Z",
          "shell.execute_reply": "2022-09-21T17:13:46.321048Z",
          "shell.execute_reply.started": "2022-09-21T17:13:46.311846Z"
        },
        "id": "0qBLwjkDwtrT"
      },
      "outputs": [],
      "source": [
        "suggestions = []\n",
        "user_id = userencoded2user.get(user_list[0])\n",
        "\n",
        "suggestions_df = movies_df.copy()[movies_df[\"movieIdx\"].isin(movies)]\n",
        "suggestions_df[\"userId\"] = user_id\n",
        "\n",
        "suggestions_df[\"score\"] = suggestions_df[\"movieIdx\"].apply(\n",
        "    lambda x: preds[movies.index(x)][0]\n",
        ")\n",
        "\n",
        "for i, movieIdx in enumerate(movies):\n",
        "    pred_rank = preds[i][0]\n",
        "    print(user_id, movieIdx, pred_rank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:13:47.821071Z",
          "iopub.status.busy": "2022-09-21T17:13:47.820572Z",
          "iopub.status.idle": "2022-09-21T17:13:47.829043Z",
          "shell.execute_reply": "2022-09-21T17:13:47.828514Z",
          "shell.execute_reply.started": "2022-09-21T17:13:47.821050Z"
        },
        "id": "3bvm6Gq_wtrU"
      },
      "outputs": [],
      "source": [
        "user_ratings = rating_df.copy()[rating_df.userId == suggestions_df.userId.tolist()[0]]\n",
        "user_ratings.rating.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-21T17:13:48.490239Z",
          "iopub.status.busy": "2022-09-21T17:13:48.489743Z",
          "iopub.status.idle": "2022-09-21T17:13:48.498857Z",
          "shell.execute_reply": "2022-09-21T17:13:48.498307Z",
          "shell.execute_reply.started": "2022-09-21T17:13:48.490217Z"
        },
        "id": "T72tj5GQwtrU"
      },
      "outputs": [],
      "source": [
        "suggestions_df.sort_values(by=[\"score\"], inplace=True, ascending=False)\n",
        "suggestions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0_H2jXBwtrU"
      },
      "source": [
        "Save the model for reuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPjdKRJpwtrU"
      },
      "outputs": [],
      "source": [
        "model.save(\"my-model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58wX4bJSwtrV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
