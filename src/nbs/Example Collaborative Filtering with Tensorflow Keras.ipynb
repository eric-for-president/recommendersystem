{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering using Tensorflow & Keras\n",
    "In our [Recommender Course](https://www.codingforentrepreneurs.com/courses/recommender/) we build a Django-based recommendation engine leveraging the Surprise ML package (among other things). This guide is made to help you upgrade your ML package by leveraging Keras and a neural network. \n",
    "\n",
    "\n",
    "Recommended requirements for running this notebook:\n",
    "- GPU-accelerated / CUDA-enabled environment\n",
    "- Cloud-based service such as Google Colab, Deepnote, and/or Paperspace\n",
    "- [Recommender]((https://github.com/codingforentrepreneurs/recommender)) code forked/cloned/downloaded, open-source datasets loaded in, and Recommender models exported\n",
    "- To export the [Recommender](https://github.com/codingforentrepreneurs/recommender)'s datasets, you can run the functions `export_rating_dataset_task` and `export_movies_dataset_task` in the `exports/tasks.py`\n",
    "-  After you run these functions, you'll have the movies dataset located in `local-cdn/media/exports/movies/latest.csv` and the ratings dataset in `local-cdn/media/exports/ratings/latest.csv`\n",
    "\n",
    "\n",
    "\n",
    "This code was directly inspired and modified from the following posts:\n",
    "- [Fast.ai's Collaborative Filtering Lesson](https://course.fast.ai/Lessons/lesson7.html)\n",
    "- [How to create a Recommendation System from scratch using Keras from the Antonai Blog](https://antonai.blog/how-to-create-a-recommendation-system-from-scratch-using-keras/)\n",
    "- [Collaborative Filtering for Movie Recommendations the Keras Docs](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
    "\n",
    "\n",
    "### Open this notebook in...\n",
    "\n",
    "[<img src=\"https://deepnote.com/buttons/launch-in-deepnote-white-small.svg\">](https://deepnote.com/launch?url=https://github.com/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)\n",
    "\n",
    "[![Run on Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (77.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tensorflow -i https://pypi.org/simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (77.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\downloads\\compressed\\recommender-main\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow scikit-learn matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.19.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\Users\\USER\\Downloads\\Compressed\\recommender-main\\.venv\\Lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:09.946362Z",
     "iopub.status.busy": "2022-09-21T17:06:09.946069Z",
     "iopub.status.idle": "2022-09-21T17:06:09.950651Z",
     "shell.execute_reply": "2022-09-21T17:06:09.950028Z",
     "shell.execute_reply.started": "2022-09-21T17:06:09.946342Z"
    },
    "id": "HCvzSnGbZKs4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:09.960324Z",
     "iopub.status.busy": "2022-09-21T17:06:09.960104Z",
     "iopub.status.idle": "2022-09-21T17:06:09.964650Z",
     "shell.execute_reply": "2022-09-21T17:06:09.964029Z",
     "shell.execute_reply.started": "2022-09-21T17:06:09.960307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# if using a cloud provider, upload your files to an \"exports folder\"\n",
    "# exports_dir = pathlib.Path().resolve() / 'exports'\n",
    "\n",
    "# if running this notebook from the root of the Recommender project\n",
    "exports_dir = pathlib.Path().resolve().parent / \"exports\"\n",
    "\n",
    "movies_exports = exports_dir / \"movies\" / \"latest.csv\"\n",
    "ratings_exports = exports_dir / \"ratings\" / \"latest.csv\"\n",
    "print(movies_exports.exists(), ratings_exports.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:09.966139Z",
     "iopub.status.busy": "2022-09-21T17:06:09.965948Z",
     "iopub.status.idle": "2022-09-21T17:06:10.017754Z",
     "shell.execute_reply": "2022-09-21T17:06:10.016986Z",
     "shell.execute_reply.started": "2022-09-21T17:06:09.966124Z"
    }
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m movies_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies_exports\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# add a \"trend\" column to combine the count of ratings with the movie's average rating\u001b[39;00m\n\u001b[32m      4\u001b[39m movies_df[\u001b[33m\"\u001b[39m\u001b[33mtrend\u001b[39m\u001b[33m\"\u001b[39m] = movies_df[\u001b[33m\"\u001b[39m\u001b[33mrating_count\u001b[39m\u001b[33m\"\u001b[39m] * movies_df[\u001b[33m\"\u001b[39m\u001b[33mrating_avg\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\Compressed\\recommender-main\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\Compressed\\recommender-main\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\Compressed\\recommender-main\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\Compressed\\recommender-main\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\Compressed\\recommender-main\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:581\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv(movies_exports)\n",
    "\n",
    "# add a \"trend\" column to combine the count of ratings with the movie's average rating\n",
    "movies_df[\"trend\"] = movies_df[\"rating_count\"] * movies_df[\"rating_avg\"]\n",
    "movies_df[\"movieIdx\"] = movies_df[\"movieIdx\"].astype(int)\n",
    "movies_df[\"movieId\"] = movies_df[\"movieId\"].astype(int)\n",
    "\n",
    "print(movies_df.shape)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the entire ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.019295Z",
     "iopub.status.busy": "2022-09-21T17:06:10.019034Z",
     "iopub.status.idle": "2022-09-21T17:06:10.039846Z",
     "shell.execute_reply": "2022-09-21T17:06:10.039211Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.019273Z"
    }
   },
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv(ratings_exports)\n",
    "print(rating_df.shape)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the movies dataset and ratings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.040852Z",
     "iopub.status.busy": "2022-09-21T17:06:10.040662Z",
     "iopub.status.idle": "2022-09-21T17:06:10.074145Z",
     "shell.execute_reply": "2022-09-21T17:06:10.073404Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.040836Z"
    }
   },
   "outputs": [],
   "source": [
    "df = rating_df.copy()\n",
    "df[\"userId\"] = df[\"userId\"].astype(int)\n",
    "df[\"movieId\"] = df[\"movieId\"].astype(int)\n",
    "df = df.join(movies_df, on=\"movieId\", rsuffix=\"_movie_df\")\n",
    "df.sort_values(by=[\"trend\"], inplace=True, ascending=False)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make note of the missing number of movies from the ratings dataset. These are missing for a couple reasons: \n",
    "- Initial dataset used had invalid ids (from the movielens datasset) - Most likely\n",
    "- Movies have been deleted from the Recommender database - Likely\n",
    "- Incorrect datatypes - Unlikely but possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.075958Z",
     "iopub.status.busy": "2022-09-21T17:06:10.075767Z",
     "iopub.status.idle": "2022-09-21T17:06:10.085651Z",
     "shell.execute_reply": "2022-09-21T17:06:10.085017Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.075943Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_data = df[df[\"movieIdx\"].isna()]\n",
    "\n",
    "number_of_missing_movies = len(missing_data.movieId.unique().tolist())\n",
    "print(number_of_missing_movies, \"movie ids missing that were rated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `NaN` columns that lack a `movieIdx` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.086700Z",
     "iopub.status.busy": "2022-09-21T17:06:10.086512Z",
     "iopub.status.idle": "2022-09-21T17:06:10.111342Z",
     "shell.execute_reply": "2022-09-21T17:06:10.110841Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.086686Z"
    }
   },
   "outputs": [],
   "source": [
    "training_df = df.copy().dropna()\n",
    "training_df[\"movieIdx\"] = training_df[\"movieIdx\"].astype(int)\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.112412Z",
     "iopub.status.busy": "2022-09-21T17:06:10.112233Z",
     "iopub.status.idle": "2022-09-21T17:06:10.129617Z",
     "shell.execute_reply": "2022-09-21T17:06:10.129112Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.112397Z"
    }
   },
   "outputs": [],
   "source": [
    "user_ids = training_df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "\n",
    "movie_ids = training_df[\"movieIdx\"].unique().tolist()\n",
    "\n",
    "df = training_df.copy()\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieIdx\"]\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_ids)\n",
    "\n",
    "df[\"rating\"] = training_df[\"rating\"].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.130513Z",
     "iopub.status.busy": "2022-09-21T17:06:10.130312Z",
     "iopub.status.idle": "2022-09-21T17:06:10.153283Z",
     "shell.execute_reply": "2022-09-21T17:06:10.152775Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.130497Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.154113Z",
     "iopub.status.busy": "2022-09-21T17:06:10.153932Z",
     "iopub.status.idle": "2022-09-21T17:06:10.201159Z",
     "shell.execute_reply": "2022-09-21T17:06:10.200590Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.154098Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    multiply,\n",
    "    concatenate,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Dense,\n",
    ")\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers as opt\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "EMBEDDING_SIZE = 500\n",
    "\n",
    "\n",
    "num_unique_users = num_users\n",
    "\n",
    "\n",
    "num_unique_movies = num_movies\n",
    "\n",
    "\n",
    "users_input = Input(shape=(1,), name=\"users_input\")\n",
    "\n",
    "\n",
    "users_embedding = Embedding(\n",
    "    num_unique_users + 1, EMBEDDING_SIZE, name=\"users_embeddings\"\n",
    ")(users_input)\n",
    "\n",
    "\n",
    "users_bias = Embedding(num_unique_users + 1, 1, name=\"users_bias\")(users_input)\n",
    "\n",
    "\n",
    "movies_input = Input(shape=(1,), name=\"movies_input\")\n",
    "\n",
    "\n",
    "movies_embedding = Embedding(\n",
    "    num_unique_movies + 1, EMBEDDING_SIZE, name=\"movies_embedding\"\n",
    ")(movies_input)\n",
    "\n",
    "\n",
    "movies_bias = Embedding(num_unique_movies + 1, 1, name=\"movies_bias\")(movies_input)\n",
    "\n",
    "\n",
    "dot_product_users_movies = multiply([users_embedding, movies_embedding])\n",
    "\n",
    "\n",
    "input_terms = dot_product_users_movies + users_bias + movies_bias\n",
    "\n",
    "\n",
    "input_terms = Flatten(name=\"fl_inputs\")(input_terms)\n",
    "\n",
    "\n",
    "# output = Dense(1, activation=\"relu\", name=\"output\")(input_terms)\n",
    "\n",
    "\n",
    "output = Dense(1, activation=\"sigmoid\", name=\"output\")(input_terms)\n",
    "\n",
    "\n",
    "output = output * (max_rating - min_rating) + min_rating\n",
    "\n",
    "\n",
    "model = Model(inputs=[users_input, movies_input], outputs=output)\n",
    "\n",
    "\n",
    "opt_adam = opt.Adam(learning_rate=0.005)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt_adam, loss=[\"mse\"], metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:07:27.863315Z",
     "iopub.status.busy": "2022-09-21T17:07:27.862678Z",
     "iopub.status.idle": "2022-09-21T17:07:27.883267Z",
     "shell.execute_reply": "2022-09-21T17:07:27.882685Z",
     "shell.execute_reply.started": "2022-09-21T17:07:27.863292Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.202063Z",
     "iopub.status.busy": "2022-09-21T17:06:10.201888Z",
     "iopub.status.idle": "2022-09-21T17:06:10.224755Z",
     "shell.execute_reply": "2022-09-21T17:06:10.224197Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.202048Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "    df, random_state=42, test_size=0.2, stratify=df.rating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:50.781014Z",
     "iopub.status.busy": "2022-09-21T17:06:50.780612Z",
     "iopub.status.idle": "2022-09-21T17:07:02.851920Z",
     "shell.execute_reply": "2022-09-21T17:07:02.851282Z",
     "shell.execute_reply.started": "2022-09-21T17:06:50.780993Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=[df_train.user.to_numpy(), df_train.movie.to_numpy()],\n",
    "    y=df_train.rating.to_numpy(),\n",
    "    batch_size=200,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(\n",
    "        [df_val.user.to_numpy(), df_val.movie.to_numpy()],\n",
    "        df_val.rating.to_numpy(),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:32.391219Z",
     "iopub.status.busy": "2022-09-21T17:13:32.390726Z",
     "iopub.status.idle": "2022-09-21T17:13:32.445178Z",
     "shell.execute_reply": "2022-09-21T17:13:32.444683Z",
     "shell.execute_reply.started": "2022-09-21T17:13:32.391197Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_preds = 100\n",
    "movies = df.sample(n=number_of_preds).movie.to_list()\n",
    "user_list = df.sample(n=1).user.to_list() * number_of_preds\n",
    "use_id = False\n",
    "if use_id:\n",
    "    user_list = [user2user_encoded.get(1)] * number_of_preds\n",
    "preds = model.predict(x=[np.array(user_list), np.array(movies)])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:46.311869Z",
     "iopub.status.busy": "2022-09-21T17:13:46.311258Z",
     "iopub.status.idle": "2022-09-21T17:13:46.321652Z",
     "shell.execute_reply": "2022-09-21T17:13:46.321048Z",
     "shell.execute_reply.started": "2022-09-21T17:13:46.311846Z"
    }
   },
   "outputs": [],
   "source": [
    "suggestions = []\n",
    "user_id = userencoded2user.get(user_list[0])\n",
    "\n",
    "suggestions_df = movies_df.copy()[movies_df[\"movieIdx\"].isin(movies)]\n",
    "suggestions_df[\"userId\"] = user_id\n",
    "\n",
    "suggestions_df[\"score\"] = suggestions_df[\"movieIdx\"].apply(\n",
    "    lambda x: preds[movies.index(x)][0]\n",
    ")\n",
    "\n",
    "for i, movieIdx in enumerate(movies):\n",
    "    pred_rank = preds[i][0]\n",
    "    print(user_id, movieIdx, pred_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:47.821071Z",
     "iopub.status.busy": "2022-09-21T17:13:47.820572Z",
     "iopub.status.idle": "2022-09-21T17:13:47.829043Z",
     "shell.execute_reply": "2022-09-21T17:13:47.828514Z",
     "shell.execute_reply.started": "2022-09-21T17:13:47.821050Z"
    }
   },
   "outputs": [],
   "source": [
    "user_ratings = rating_df.copy()[rating_df.userId == suggestions_df.userId.tolist()[0]]\n",
    "user_ratings.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:48.490239Z",
     "iopub.status.busy": "2022-09-21T17:13:48.489743Z",
     "iopub.status.idle": "2022-09-21T17:13:48.498857Z",
     "shell.execute_reply": "2022-09-21T17:13:48.498307Z",
     "shell.execute_reply.started": "2022-09-21T17:13:48.490217Z"
    }
   },
   "outputs": [],
   "source": [
    "suggestions_df.sort_values(by=[\"score\"], inplace=True, ascending=False)\n",
    "suggestions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
